# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vTMBbsI2R3tDqHKaLmGhaMYXK6z19YNy

**Breast cancer detection using Python**
"""

#Import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#Load the data
from google.colab import files
uploaded = files.upload()
df = pd.read_csv('breast-cancer.csv')
df.head(7)

df.tail(7)

#Counting the no  of rows and column in the data set
df.shape

#count the number of empty (NaN,NAN,na)values in each column
df.isna().sum()

#Drop the column with all missing values
df = df.dropna(axis=1)

#Get the new count of the number of rows and columns
df.shape

#Get a count of the number of  OF Malognant (M) or Bengin (B) cells
df['diagnosis'].value_counts()

#visualize the count
sns.countplot(df['diagnosis'], label='count')

#Look at the data types to see which columns needd to be encoded
df.dtypes

#Encode the categorical data values
from sklearn.preprocessing import  LabelEncoder
labelencoder_Y = LabelEncoder()
df.iloc[:,1] = labelencoder_Y.fit_transform(df.iloc[:,1].values)

#cfeate a pair plot
sns.pairplot(df.iloc[:,1:5], hue='diagnosis')

#Print the first 5 rows of the new data
df.head(5)

#Get the correlation of the columns
df.iloc[:,1:12].corr()

#Visualize the correlation
plt.figure(figsize=(20,20))
sns.heatmap(df.iloc[:,1:31].corr(), annot=True,fmt='.0%')

#Split the data set into independent (x) and dependent (Y) data sets
X = df.iloc[:,2:31].values
Y = df.iloc[:,1].values

#plit the data set into 75% training and 25% testing
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25 , random_state = 0)

#Scale the data(Feature Scaling)
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train  = sc.fit_transform(X_train)
X_test = sc.fit_transform(X_test)
X

#Create a function for the models
def models(X_train,Y_train):
   #Logistic Regression
   from sklearn.linear_model import LogisticRegression
   log = LogisticRegression(random_state=0)
   log.fit(X_train,Y_train)

   #Decision Tree
   from sklearn.tree import DecisionTreeClassifier
   tree = DecisionTreeClassifier(criterion = 'entropy',random_state = 0)
   tree.fit(X_train , Y_train)

   #Random Forest Classifier
   from sklearn.ensemble import RandomForestClassifier
   forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy',random_state =0)
   forest.fit(X_train,Y_train)

   #Print  the models accuracy on the training data
   print('[0]Logistic Regression Training Accuracy:',log.score(X_train,Y_train))
   print('[1]Decision Tree Training Accuracy:',tree.score(X_train,Y_train))
   print('[2]Random Forest Classifier Training Accuracy:',forest.score(X_train,Y_train))

   return log,tree,forest

#Geeting all of the Models
model = models(X_train, Y_train)

#test model accuracy on test data on confusion matrix
from sklearn.metrics import confusion_matrix
for i in range(len(model)):
  print('Model ',i)
  cm = confusion_matrix(Y_test, model[0].predict(X_test))
  TP = cm[0][0]
  TN = cm[1][1]
  FN = cm[1][0]
  FP = cm[0][1]
  print(cm)
  print('Testing Accuracy = ', (TP + TN )/ ( TP + TN + FN + FP))
  print()

# Print the pridiction of random Forest Classifier Model
pred = model[2].predict(X_test)
print(pred)
print()
print(Y_test)
